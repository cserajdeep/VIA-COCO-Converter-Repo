{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "pip install git+https://github.com/amikelive/coco-annotator.git#egg=COCOAnnotator"
      ],
      "metadata": {
        "id": "RbetYaDyvqC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Here is an example of how you could write such a Python script using the `via` library. This code assumes that your input data is in a directory called \"input_data\" and will save output files into another folder called \"output_data\". You can modify this as needed for your own use case.\n",
        "\n",
        "1) First, install the via package if it's not already installed on your system by running pip install git+https://github.com/amikelive/coco-annotator.git#egg=COCOAnnotator in your terminal or command prompt.\n",
        "\n",
        "2) Create two folders - one named 'input\\_data' (or whatever name you prefer), which will contain all your original images along with their annotations in COCO format; and another folder named 'output\\_data', where we'll store our finalized datasets after processing them through the script.\n",
        "\n",
        "3) Inside the 'input\\_data' folder, create subfolders according to each dataset category containing its respective image files and annotation jsons. For instance, let's say there are three categories - 'car', 'person', and 'traffic light'. Then inside the 'input\\_data' folder, create these 3 additional folders too.\n",
        "\n",
        "4) Now copy over some sample images and corresponding annotation jsons for each category into their respective folders within 'input\\_data'. The filenames should match exactly between the image and annotation json so that they can be matched up during conversion process.\n",
        "\n",
        "5) Next, open your favorite IDE or text editor and start writing your Python script. We're going to need several imports at the beginning like below:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "​\n",
        "# Importing required libraries for working with COCO formats\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.mask import decode\n",
        "\n",
        "# Importing required classes from the coco-annotator library\n",
        "from core.annotation import AnnotationController\n",
        "from utils.logger import get_logger\n",
        "logger = get_logger()\n",
        "​\n",
        "\n",
        "\n",
        "# Define the paths to both the input and output directories:\n",
        "\n",
        "root_dir = '/path/to/your/root/directory/'\n",
        "input_folder = f'{root_dir}/input_data'\n",
        "output_folder = f'{root_dir}/output_data'\n",
        "​\n",
        "\n",
        "\n",
        "# Let's define a function to recursively search through a given directory and return a list of all found.json files:\n",
        "\n",
        "def find_files(directory):\n",
        "  \"\"\"Recursively finds all.json files under a given directory\"\"\"\n",
        "  results = []\n",
        "​\n",
        "  for entry in os.scandir(directory):\n",
        "    if entry.is_file():\n",
        "      if entry.name.endswith(\".json\"):\n",
        "          results.append(entry.path)\n",
        "​\n",
        "    elif entry.is_dir():\n",
        "      results += find_files(entry.path)\n",
        "​\n",
        "  return results\n",
        "​\n",
        "\n",
        "# Use the above function to iterate through all.json files present in the input\\_data folder and load them individually into memory as COCO objects:\n",
        "# Find all.json files in the input_data folder\n",
        "json_files = find_files(input_folder)\n",
        "​\n",
        "# Load each.json file as a COCO object\n",
        "coco_objs = [COCO(f) for f in json_files]\n",
        "​\n",
        "\n",
        "# Define a mapping dictionary that maps the desired label names to their integer IDs used internally by Mask RCNN models:\n",
        "\n",
        "# Mapping dict to map human readable labels to internal model ids\n",
        "label_map = {\n",
        "    'car': 0, \n",
        "    'person': 1,  \n",
        "    'traffic light': 2  \n",
        "}\n",
        "​\n",
        "\n",
        "\n",
        "# Finally, loop through every loaded COCO object and filter out only those instances whose \"category\" field matches any key in the label\\_map defined earlier. Save filtered annotations back to individual.JSON files in the output\\_data folder while also converting bounding box coordinates to normalized form (values between 0 and 1). Note that depending upon the complexity of your dataset, this step may take some time since we have to parse and reformat large amounts of data here:\n",
        "# Loop through all loaded COCO objs and filter based on the provided label_map\n",
        "for i, coco_obj in enumerate(coco_objs):\n",
        "    \n",
        "    # Get img id -> ann id mappings for current obj\n",
        "    img_ids = coco_obj.getImgIds()\n",
        "    cat_ids = coco_obj.getCatIds()\n",
        "\n",
        "    # Iterate through all images in the current COCO obj\n",
        "    for img_id in tqdm(img_ids):\n",
        "    \n",
        "        # Fetch all annotations associated with the current image\n",
        "        anns = coco_obj.loadAnns(coco_obj.getAnnIds(imgIds=[img_id], catIds=cat_ids))\n",
        "        \n",
        "        # Filter out unwanted annotations \n",
        "        filtered_anns = [a for a in anns if a['category_id'] in label_map.keys()]\n",
        "                    \n",
        "        # Convert bbox coords to normalized values\n",
        "        width, height = coco_obj.imgs[img_id]['width'], coco_obj.imgs[img_id]['height']\n",
        "        converted_anns = [{k:(v*1.0 / max(width, height) if k == 'bbox' else v) for k, v in ann.items()} for ann in filtered_anns]\n",
        "                \n",
        "        # Write filtered annotations to disk in.JSON format\n",
        "        filename = str(i)+ '_' +str(img_id) + '.json'\n",
        "        filepath = os.path.join(output_folder, filename)\n",
        "        with open(filepath,'w') as outfile: \n",
        "            json.dump({'categories': [{'id': int(label_map[c]), 'name': c} for c in label_map.keys()],\n",
        "                        'annotations':converted_anns},\n",
        "                      outfile)"
      ],
      "metadata": {
        "id": "irnXLlCtvM-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}